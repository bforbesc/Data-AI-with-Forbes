{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI's Fuel: From Words to Tokens\n",
        "\n",
        "This notebook tells a small story about turning a sentence into something a computer can use: numbers. We begin with plain text and end with a tensor made of one-hot vectors. Each step is short and focused so that no prior knowledge of tokenization is required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 — Provide the sentence\n",
        "Edit the cell below to set the sentence to transform. Keep the variable name exactly as `TEXT`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEXT = \"Tokens are text as numbers!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 — Prepare the words\n",
        "We normalize the sentence by making it lowercase and removing a couple of punctuation marks. Then we split on spaces to see the words as separate pieces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "clean = TEXT.lower().replace(\"!\", \"\").replace(\".\", \"\")\n",
        "tokens = clean.split()\n",
        "print(\"Tokens:\", tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 — Collect the vocabulary\n",
        "From the words we saw, we gather the unique set and fix an order. This ordered list will define the columns of our vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = sorted(set(tokens))\n",
        "V = len(vocab)\n",
        "print(\"Vocabulary:\", vocab)\n",
        "print(\"Vocabulary size:\", V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4 — Give each word an index\n",
        "Each vocabulary word receives a unique integer. These numbers will be used to position the 1s inside our vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "print(\"word2idx:\", word2idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5 — Define one-hot vectors\n",
        "A one-hot vector has zeros everywhere and a single 1 at the index of the word. The length of the vector equals the vocabulary size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot(idx, vocab_size):\n",
        "    vec = np.zeros(vocab_size, dtype=int)\n",
        "    vec[idx] = 1\n",
        "    return vec\n",
        "print(\"Example one-hot (index 0):\", one_hot(0, V))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6 — Translate the sentence into indices\n",
        "We replace each token in the sentence with its index from the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "token_indices = [word2idx[t] for t in tokens]\n",
        "print(\"Token indices:\", token_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7 — Build one-hot vectors and stack them\n",
        "For each index we create a one-hot vector, then we stack all vectors into a 2D array. The shape tells us: rows are tokens, columns are vocabulary entries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "one_hots = [one_hot(i, V) for i in token_indices]\n",
        "tensor = np.stack(one_hots, axis=0)\n",
        "print(\"Tensor shape:\", tensor.shape)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8 — Read the alignment\n",
        "Here are the row tokens and the column vocabulary. Reading any row shows a single 1 beneath the matching vocabulary word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Row tokens in order:\", tokens)\n",
        "print(\"Vocabulary (column order):\", vocab)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
