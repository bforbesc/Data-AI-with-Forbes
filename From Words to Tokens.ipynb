{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word Tokenization to One‚ÄëHot Tensors (Python + NumPy)\n",
        "\n",
        "**Goal:** Convert a simple sentence into tokens, map words to indices, build one‚Äëhot vectors, and stack them into a NumPy tensor ‚Äî beginner friendly and self‚Äëcontained.\n",
        "\n",
        "We stop at step 8 (no embeddings), and there is no separate Dependencies section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) üìù Sample sentence & tokenization  \n",
        "**What this does:** Normalizes the text (lowercase, drop simple punctuation) and splits on spaces to get beginner‚Äëfriendly word tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Minimal setup kept inside code (no \"Dependencies\" section)\n",
        "import numpy as np\n",
        "\n",
        "# Our example sentence\n",
        "sentence = \"Hello world! Welcome to NumPy tokenization.\"\n",
        "\n",
        "# Basic cleanup: lowercase & remove a couple of punctuation marks\n",
        "clean = sentence.lower().replace(\"!\", \"\").replace(\".\", \"\")\n",
        "\n",
        "# Split on whitespace to get tokens\n",
        "tokens = clean.split()\n",
        "\n",
        "print(\"Tokens:\", tokens)\n",
        "# Expected: ['hello', 'world', 'welcome', 'to', 'numpy', 'tokenization']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) üìö Build a vocabulary  \n",
        "**What this does:** Collects unique words and fixes an order, giving us a stable set of columns for vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Unique words (sorted so the order is deterministic)\n",
        "vocab = sorted(set(tokens))\n",
        "V = len(vocab)\n",
        "\n",
        "print(\"Vocabulary:\", vocab)\n",
        "print(\"Vocabulary size:\", V)\n",
        "# Example:\n",
        "# Vocabulary: ['hello', 'numpy', 'tokenization', 'to', 'welcome', 'world']\n",
        "# Vocabulary size: 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) üîó Create word ‚Üî index mappings  \n",
        "**What this does:** Assigns each vocabulary word a unique integer index so we can look up vector positions quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "\n",
        "print(\"word2idx:\", word2idx)\n",
        "# Example: {'hello': 0, 'numpy': 1, 'tokenization': 2, 'to': 3, 'welcome': 4, 'world': 5}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) üéØ One‚Äëhot encoding helper  \n",
        "**What this does:** Defines a tiny function that turns an index into a one‚Äëhot vector (all zeros except a 1 at that index)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def one_hot(idx, vocab_size):\n",
        "    \"\"\"\n",
        "    Create a one-hot vector of length `vocab_size` with a 1 at `idx`.\n",
        "    \"\"\"\n",
        "    vec = np.zeros(vocab_size, dtype=int)\n",
        "    vec[idx] = 1\n",
        "    return vec\n",
        "\n",
        "# Quick sanity check:\n",
        "print(\"One-hot for index 0:\", one_hot(0, V))\n",
        "# Example: [1 0 0 0 0 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) üî¢ Map tokens ‚Üí indices  \n",
        "**What this does:** Converts each token in the sentence into its integer index according to the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "token_indices = [word2idx[t] for t in tokens]\n",
        "print(\"Token indices:\", token_indices)\n",
        "# Example: [0, 5, 4, 3, 1, 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) üß± Convert indices ‚Üí one‚Äëhot vectors & stack into a tensor  \n",
        "**What this does:** Builds a one‚Äëhot vector per token and stacks them into a 2D NumPy array (tensor) with shape `(num_tokens, vocab_size)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "one_hots = [one_hot(i, V) for i in token_indices]\n",
        "\n",
        "# Stack rows to form a (num_tokens, vocab_size) tensor\n",
        "tensor = np.stack(one_hots, axis=0)\n",
        "\n",
        "print(\"Shape of tensor:\", tensor.shape)\n",
        "print(\"Tensor:\\n\", tensor)\n",
        "# Example shape: (6, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) üîç Inspecting the result (tokens vs. columns)  \n",
        "**What this does:** Clarifies how rows/columns line up so you can read the tensor meaningfully."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "print(\"Tokens (row order):\", tokens)\n",
        "print(\"Vocabulary (column order):\", vocab)\n",
        "\n",
        "# Reading tip:\n",
        "# - Each ROW corresponds to a token in the original order: ['hello', 'world', 'welcome', 'to', 'numpy', 'tokenization']\n",
        "# - Each COLUMN corresponds to a vocab entry (alphabetical above), e.g. ['hello','numpy','tokenization','to','welcome','world']\n",
        "# So the row for 'world' has a 1 in the 'world' column, and 0 elsewhere."
      ]
    }
  ]
}